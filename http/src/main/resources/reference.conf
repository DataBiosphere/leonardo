# NOTE: commented fields are overridden in firecloud-develop with templated values
# Fields with "replace_me" are also expected to be overridden, but need to be in
# this file to allow referential integrity.

application {
  applicationName = "leonardo"
  #leoGoogleProject = "broad-dsde-dev"
  leoServiceAccountJsonFile = "replace_me"
  leoServiceAccountEmail = "replace_me"
}

# Google Cloud dataproc configuration
dataproc {
  dataprocDefaultRegion = "us-central1"
  #dataprocZone = "us-central1-a"
  defaultScopes = [
    "https://www.googleapis.com/auth/userinfo.email",
    "https://www.googleapis.com/auth/source.read_only",
    "https://www.googleapis.com/auth/logging.write",
    "https://www.googleapis.com/auth/devstorage.full_control",
    "https://www.googleapis.com/auth/userinfo.profile",
    "https://www.googleapis.com/auth/cloud.useraccounts.readonly",
    "https://www.googleapis.com/auth/bigquery"
  ]
  runtimeDefaults {
    numberOfWorkers = 0
    masterMachineType = "n1-standard-4"
    masterDiskSize = 100
    workerMachineType = "n1-standard-4"
    workerDiskSize = 100
    numberOfWorkerLocalSSDs = 0
    numberOfPreemptibleWorkers = 0
  }
  # This image is used for legacy jupyter image where hail is compatible with earlier version of spark
  legacyCustomDataprocImage = "projects/broad-dsp-gcr-public/global/images/custom-leo-image-dataproc-1-2-79-debian9-2d78533"
  customDataprocImage = "projects/broad-dsp-gcr-public/global/images/custom-leo-image-dataproc-1-4-15-debian9-2d78533"

  dataprocReservedMemory = 6g
}

gce {
  zone = "us-central1-a"
  customGceImage = "projects/broad-dsp-gcr-public/global/images/custom-leo-image-gce-debian9-2d78533"
  defaultScopes = [
    "https://www.googleapis.com/auth/userinfo.email",
    "https://www.googleapis.com/auth/userinfo.profile",
    "https://www.googleapis.com/auth/cloud-platform"
  ]
  runtimeDefaults {
    machineType = "n1-standard-4"
    diskSize = 100
  }
  gceReservedMemory = 1g
}

groups {
  #subEmail = "google@{{$appsSubdomain}}"
  #dataprocImageProjectGroupName = "dataproc-image-project-group"
  #dataprocImageProjectGroupEmail = ${groups.dataprocImageProjectGroupName}"@{{$appsSubdomain}}"
}

image {
  welderImage = "us.gcr.io/broad-dsp-gcr-public/welder-server:59be71a"
  jupyterImage =  "us.gcr.io/broad-dsp-gcr-public/terra-jupyter-gatk:0.0.13"
  legacyJupyterImage = "us.gcr.io/broad-dsp-gcr-public/leonardo-jupyter:5c51ce6935da"
  proxyImage = "broadinstitute/openidc-proxy:2.3.1_2"

  jupyterContainerName = "jupyter-server"
  rstudioContainerName = "rstudio-server"
  welderContainerName = "welder-server"
  proxyContainerName = "proxy-server"

  jupyterImageRegex = "us.gcr.io/broad-dsp-gcr-public/([a-z0-9-_]+):(.*)"
  rstudioImageRegex = "us.gcr.io/anvil-gcr-public/([a-z0-9-_]+):(.*)"
  broadDockerhubImageRegex = "broadinstitute/([a-z0-9-_]+):(.*)"
}

welder {
  welderDisabledNotebooksDir = "/home/jupyter-user"
  welderEnabledNotebooksDir = "/home/jupyter-user/notebooks"
  # Set to deploy welder to clusters with the given label
  deployWelderLabel = "saturnVersion"

  # Set to upgrade welder on clusters with the given label
  updateWelderLabel = "saturnVersion"

  # Leo will only deploy welder to clusters created after this date.
  # Clusters created prior to this date will not have welder deployed and will have delocalization disabled.
  deployWelderCutoffDate = "2019-08-01"

  welderReservedMemory = 768m
}

# cluster scripts and config
clusterResources {
  initActionsScript = "init-actions.sh"
  gceInitScript = "gce-init.sh"
  startupScript = "startup.sh"
  shutdownScript = "shutdown.sh"
  jupyterDockerCompose = "jupyter-docker-compose.yaml"
  jupyterDockerComposeGce = "jupyter-docker-compose-gce.yaml"
  rstudioDockerCompose = "rstudio-docker-compose.yaml"
  proxyDockerCompose = "proxy-docker-compose.yaml"
  welderDockerCompose = "welder-docker-compose.yaml"
  proxySiteConf = "cluster-site.conf"
  jupyterNotebookConfigUri = "jupyter_notebook_config.py"
  jupyterNotebookFrontendConfigUri = "notebook.json"
  customEnvVarsConfigUri = "custom_env_vars.env"
}

clusterFiles {
  configFolderPath = "/etc/"
  jupyterServerCrt = "jupyter-server.crt"
  jupyterServerKey = "jupyter-server.key"
  jupyterRootCaPem = "rootCA.pem"
  jupyterRootCaKey = "rootCA.key"
}

clusterDnsCache {
  cacheExpiryTime = 5 seconds
  cacheMaxSize = 10000
}

mysql {
  profile = "slick.jdbc.MySQLProfile$"
  batchSize = 2000
  db {
    driver = "com.mysql.cj.jdbc.Driver"
    #url = "jdbc:mysql://mysql/leonardo
    #user = "dbUser"
    #password = "pass"
    connectionTimeout = 5000
    numThreads = 200
  }
  concurrency = 120
}

# Liquibase configuration
liquibase {
  changelog = "org/broadinstitute/dsde/workbench/leonardo/liquibase/changelog.xml"
  initWithLiquibase = true
}

sam {
  server = "replace_me"
}

proxy {
  # Should match the proxy wildcard cert
  #proxyDomain = ".firecloud.org"
  proxyUrlBase = "https://leo/proxy/"
  proxyPort = 443
  proxyProtocol = "tcp"
  firewallRuleName = "leonardo-notebooks-rule"
  networkTag = "leonardo"
  projectVPCNetworkLabel = "vpc-network-name"
  projectVPCSubnetLabel = "vpc-subnetwork-name"
  dnsPollPeriod = 15 seconds
  tokenCacheExpiryTime = 60 minutes
  tokenCacheMaxSize = 10000
  internalIdCacheExpiryTime = 2 minutes
  internalIdCacheMaxSize = 10000
}

swagger {
  #googleClientId = "client_id"
  #realm = "broad-dsde-dev"
}

monitor {
  pollPeriod = 15 seconds
  maxRetries = -1  # means retry forever
  recreateCluster = true
  # Defines timeouts for cluster status transitions. If a status is not listed there is no timeout.
  # In the case of a Starting cluster, a timeout will transition it back to Stopped. Otherwise,
  # a timeout will transition it to Error status.
  statusTimeouts {
    creating = 1 hour
    starting = 20 minutes
    deleting = 1 hour
  }
}

# akka values are not specified here because they are only picked up in the leonardo.conf

# Authorization implementation config
auth {
  providerClass = "org.broadinstitute.dsde.workbench.leonardo.auth.sam.SamAuthProvider"
  providerConfig {
    samServer = ${sam.server}
    petTokenCacheEnabled = true
    petTokenCacheExpiryTime = 60 minutes
    petTokenCacheMaxSize = 1000
    notebookAuthCacheEnabled = true
    notebookAuthCacheExpiryTime = 30 minutes
    notebookAuthCacheMaxSize = 1000
    providerTimeout = 30 seconds
  }
}

# Implement and specify a class that will provide appropriate service accounts
serviceAccounts {
  providerClass = "org.broadinstitute.dsde.workbench.leonardo.auth.sam.PetClusterServiceAccountProvider"
  providerConfig {
    leoServiceAccountJsonFile = ${application.leoServiceAccountJsonFile}
    leoServiceAccountEmail = ${application.leoServiceAccountEmail}
    samServer = ${sam.server}
    petTokenCacheExpiryTime = 60 minutes
    petTokenCacheMaxSize = 1000
    providerTimeout = 30 seconds
  }
}

pubsub {
  #pubsubGoogleProject = "broad-dsde-dev"
  #topicName = "leonardo-pubsub"
  queueSize = 100
}

autoFreeze {
  enableAutoFreeze = true
  dateAccessedMonitorScheduler = 1 minute
  autoFreezeAfter = 30 minutes
  autoFreezeCheckScheduler = 1 minute
  maxKernelBusyLimit = 24 hours
}

jupyterConfig {
  # https://*.npmjs.org and 'unsafe-eval' needed for jupyterlab
  # https://csp-evaluator.withgoogle.com/ can be used to evaluate CSP syntax
  contentSecurityPolicy = "frame-ancestors 'self' http://localhost:3000 http://localhost:4200 https://localhost:443 *.terra.bio https://bvdp-saturn-prod.appspot.com https://bvdp-saturn-staging.appspot.com https://bvdp-saturn-perf.appspot.com https://bvdp-saturn-alpha.appspot.com https://bvdp-saturn-dev.appspot.com https://all-of-us-workbench-test.appspot.com https://all-of-us-rw-staging.appspot.com https://all-of-us-rw-stable.appspot.com https://stable.fake-research-aou.org https://workbench.researchallofus.org terra.biodatacatalyst.nhlbi.nih.gov *.terra.biodatacatalyst.nhlbi.nih.gov; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://apis.google.com ; style-src 'self' 'unsafe-inline'; connect-src 'self' wss://*.broadinstitute.org:* wss://notebooks.firecloud.org:* *.googleapis.com https://*.npmjs.org https://data.broadinstitute.org https://s3.amazonaws.com/igv.broadinstitute.org/ https://s3.amazonaws.com/igv.org.genomes/ https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js"
}

zombieClusterMonitor {
  enableZombieClusterMonitor = true
  pollPeriod = 4 hours
  creationHangTolerance = 1 hour
  concurrency = 100
}

clusterToolMonitor {
  pollPeriod = 2 minutes
}

leoExecutionMode {
  backLeo = true
}

clusterBucket {
  # number of days the staging bucket should continue to exist after a cluster is deleted
  stagingBucketExpiration = 10 days
}

ui {
  terraLabel = "saturnAutoCreated"
  allOfUsLabel = "all-of-us"
}
