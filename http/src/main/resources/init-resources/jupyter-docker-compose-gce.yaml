# Note: we need to stay on docker-compose version 2 because version 3 doesn't support
# configuring memory options in container mode. See discussion in:
# https://docs.docker.com/compose/compose-file/#resources
# https://github.com/docker/compose/issues/4513
version: '2.4'
services:
  jupyter:
    container_name: "${JUPYTER_SERVER_NAME}"
    image: "${JUPYTER_DOCKER_IMAGE}"
    # Override entrypoint with a placeholder to keep the container running indefinitely.
    # The cluster init script will run some scripts as root and then start pyspark as
    # jupyter-user via docker exec.
    # -F will follow the log when the log is created.
    entrypoint: "tail -F ${NOTEBOOKS_DIR}/jupyter.log"
    ports:
      - "8000:8000"
    networks:
      - app_network
    volumes:
      # shared with welder
      - "/mnt/disks/work:${NOTEBOOKS_DIR}"
    restart: always
    environment:
      GOOGLE_PROJECT: "${GOOGLE_PROJECT}"
      WORKSPACE_NAMESPACE: "${GOOGLE_PROJECT}"
      CLUSTER_NAME: "${RUNTIME_NAME}"
      RUNTIME_NAME: "${RUNTIME_NAME}"
      OWNER_EMAIL: "${OWNER_EMAIL}"
      # Value must be the string "true" to enable.
      WELDER_ENABLED: "${WELDER_ENABLED}"
      NOTEBOOKS_DIR: "${NOTEBOOKS_DIR}"
      PIP_USER: "false"
      PIP_TARGET: "${NOTEBOOKS_DIR}/packages"
      R_LIBS: "${NOTEBOOKS_DIR}/packages"
    env_file:
      - /var/google_application_credentials.env
      - /var/custom_env_vars.env
    # See https://docs.docker.com/engine/reference/run/#user-memory-constraints
    mem_limit: ${MEM_LIMIT}   # hard limit on memory consumption by the container
networks:
  app_network:
    external: true
