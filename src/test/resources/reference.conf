// a test DB is required.  Here's an example command to run one locally

//docker run --name mysql-leonardo \
// -e MYSQL_ROOT_PASSWORD=leonardo-test \
// -e MYSQL_USER=leonardo-test \
// -e MYSQL_PASSWORD=leonardo-test \
// -e MYSQL_DATABASE=leotestdb \
// -d -p 3306:3306 mysql/mysql-server:5.6

mysql {
  profile = "slick.jdbc.MySQLProfile$"
  batchSize = 5000
  host = "localhost"
  //host = ${?MYSQL_HOST}
  port = 3311
  //port = ${?MYSQL_PORT}
  db {
    driver = "com.mysql.cj.jdbc.Driver"
    url = "jdbc:mysql://"${mysql.host}":"${mysql.port}"/leotestdb?createDatabaseIfNotExist=true&useSSL=false&rewriteBatchedStatements=true&nullNamePatternMatchesAll=true"
    user = "leonardo-test"
    password = "leonardo-test"
    connectionTimeout = "5 seconds"  // default of 1 sec sometimes too short for docker local mysql
  }
}

liquibase {
  changelog = "org/broadinstitute/dsde/workbench/leonardo/liquibase/changelog.xml"
  initWithLiquibase = true
}

dataproc {
  applicationName = "test:leonardo"
  serviceAccountEmail = "test@test.com"
  dataprocDefaultRegion = "testregion"
  dataprocZone = "test-zone"
  leoGoogleProject = "test-bucket"
  dataprocDockerImage = "testrepo/test"
  clusterUrlBase = "http://leonardo/"
  defaultExecutionTimeout = 30 minutes
  jupyterServerName = "test-server"
  welderServerName = "test-welder-server"
  createClusterAsPetServiceAccount = false
  firewallRuleName = "test-rule"
  networkTag = "test-tag"
  vpcNetwork = "test-network"
  vpcSubnet = "test-subnet"
  welderDockerImage="testwelderrepo/test"
}

proxy {
  jupyterProxyDockerImage = "testrepo/test"
  proxyServerName = "test-proxy-server"
  jupyterPort = 8001,
  jupyterProtocol = "tcp",
  jupyterDomain = ".jupyter.firecloud.org",
  dnsPollPeriod = "1s"
  cacheExpiryTime = "60 minutes"
  cacheMaxSize = 100
}

clusterFiles {
  configFolderPath = "src/test/resources/"
  jupyterServerCrt = "test-server.crt"
  jupyterServerKey = "test-server.key"
  jupyterRootCaPem = "test-server.pem"
  jupyterRootCaKey = "test-server.key"
}

clusterResources {
  initActionsScript = "test-init-actions.sh"
  jupyterDockerCompose = "test-jupyter-docker-compose.yaml"
  rstudioDockerCompose = "test-rstudio-docker-compose.yaml"
  proxyDockerCompose = "test-proxy-docker-compose.yaml"
  proxySiteConf = "test-site.conf"
  googleSignInJs = "test-google_sign_in.js"
  extensionEntry = "test-extension_entry.js"
  jupyterLabGooglePlugin = "test-google_plugin_jupyterlab.js"
  safeModeJs = "test-safe-mode.js"
  editModeJs = "test-edit-mode.js"
  jupyterNotebookConfigUri = "jupyter_notebook_config.py"
  welderDockerCompose = "test-welder-docker-compose.yaml"
}

clusterDefaults {
  numberOfWorkers = 0
  masterMachineType = "test-master-machine-type"
  masterDiskSize = 100
  workerMachineType = "test-worker-machine-type"
  workerDiskSize = 100
  numberOfWorkerLocalSSDs = 0
  numberOfPreemptibleWorkers = 0
}

sam {
  server = "https://sam.test.org:443"
}

swagger {
  googleClientId = "test.apps.googleusercontent.com"
  realm = "broad-dsde-test"
}

monitor {
  pollPeriod = 1 second
  maxRetries = -1  # means retry forever
  recreateCluster = true
}

auth {
  providerClass = "org.broadinstitute.dsde.workbench.leonardo.auth.SamAuthProvider"
  providerConfig = {
    samServer = "https://sam.test.org:443"
    petTokenCacheEnabled = true
    petTokenCacheExpiryTime = "60 minutes"
    petTokenCacheMaxSize = 100
  }

  whitelistProviderConfig = {
    whitelist = ["user1@example.com"]
  }

  samAuthProviderConfig = {
    samServer = "https://sam.test.org:443"
    petTokenCacheEnabled = true
    petTokenCacheExpiryTime = 60 minutes
    petTokenCacheMaxSize = 100
    providerTimeout = 1 second
    notebookAuthCacheEnabled = true
    notebookAuthCacheMaxSize  = 100
    notebookAuthCacheExpiryTime = 60 minutes
  }

  alwaysYesProviderConfig = {
    CreateClusters = true
    GetClusterStatus = true
    ConnectToCluster = true
    SyncDataToCluster = true
    DeleteCluster = true
    StopStartCluster = true
  }

  alwaysNoProviderConfig = {
    CreateClusters = false
    GetClusterStatus = false
    ConnectToCluster = false
    SyncDataToCluster = false
    DeleteCluster = false
    StopStartCluster = false
  }

  readOnlyProviderConfig = {
    CreateClusters = false
    GetClusterStatus = true
    ConnectToCluster = false
    SyncDataToCluster = false
    DeleteCluster = false
    StopStartCluster = false
  }

  syncOnlyProviderConfig = {
    CreateClusters = false
    GetClusterStatus = true
    ConnectToCluster = false
    SyncDataToCluster = true
    DeleteCluster = false
    StopStartCluster = false
  }

  optimizedListClustersConfig = {
    canSeeClustersInAllProjects = false
    canSeeAllClustersIn = ["visible-project"]
    GetClusterStatus = true

    //don't care about these for this test
    CreateClusters = false
    ConnectToCluster = false
    SyncDataToCluster = false
    DeleteCluster = false
    StopStartCluster = false
  }
}

serviceAccounts {
  providerClass = "org.broadinstitute.dsde.workbench.leonardo.auth.MockPetsPerProjectServiceAccountProvider"
  config = {
    leoServiceAccountEmail = "leo@leo.loe"
    leoServiceAccountPemFile = "test.pem"
    providerTimeout = 1 second
  }
}

akka.ssl-config {
  trustManager = {
    stores = [
      {
        type = "PEM"
        path = "src/test/resources/test-rootCA.pem"
      }
    ]
  }
}

autoFreeze {
  #Change to true once auto freeze is ready for prod
  enableAutoFreeze = true
  dateAccessedMonitorScheduler = 1 second
  autoFreezeAfter = 15 minutes
  autoFreezeCheckScheduler = 10 second
}

jupyterConfig {
  # https://*.npmjs.org and 'unsafe-eval' needed for jupyterlab
  contentSecurityPolicy = "frame-ancestors 'self' http://localhost:3000 https://bvdp-saturn-prod.appspot.com https://bvdp-saturn-dev.appspot.com https://localhost:443; script-src 'self' 'unsafe-inline' 'unsafe-eval' https://apis.google.com ; style-src 'self' 'unsafe-inline'; connect-src 'self' wss://*.broadinstitute.org:* *.googleapis.com https://*.npmjs.org"
}

zombieClusterMonitor {
  enableZombieClusterMonitor = true
  pollPeriod = 1 second
  creationHangTolerance = 9 second
}

clusterDnsCache {
  cacheExpiryTime = 2 seconds
  cacheMaxSize = 100
}

leoExecutionMode {
  backLeo = true
}
